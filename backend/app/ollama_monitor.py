"""
OLLAMA MONITOR - AI-Powered System Monitoring and Log Analysis
===========================================================

This module uses Ollama's intelligence for comprehensive system monitoring:
- Log analysis with natural language understanding
- Anomaly detection using pattern recognition
- Performance optimization suggestions from AI
- Error diagnosis and automated fixes
- System health interpretation and recommendations
- Predictive maintenance alerts
- Real-time intelligent monitoring
- Automated incident response
"""

import asyncio
import json
import logging
import re
import time
import psutil
import threading
from typing import Dict, List, Optional, Any, Tuple, Union, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict, deque
import statistics
from pathlib import Path
import gzip
import hashlib

from .ollama_everything import ollama_everything, OllamaTask, OllamaTaskType, OllamaResult
from .valkey_integration import valkey_connection_manager
from .config import settings

logger = logging.getLogger(__name__)


class AlertSeverity(str, Enum):
    """Alert severity levels."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"
    EMERGENCY = "emergency"


class MonitoringType(str, Enum):
    """Types of monitoring performed."""
    SYSTEM_HEALTH = "system_health"
    LOG_ANALYSIS = "log_analysis"
    PERFORMANCE_MONITORING = "performance_monitoring"
    ERROR_DETECTION = "error_detection"
    ANOMALY_DETECTION = "anomaly_detection"
    SECURITY_MONITORING = "security_monitoring"
    APPLICATION_MONITORING = "application_monitoring"
    NETWORK_MONITORING = "network_monitoring"
    DATABASE_MONITORING = "database_monitoring"


@dataclass
class SystemMetrics:
    """System performance metrics."""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    disk_usage_percent: float
    network_io: Dict[str, int]
    disk_io: Dict[str, int]
    process_count: int
    load_average: List[float]
    temperature: Optional[float] = None
    
    @classmethod
    def capture_current(cls) -> 'SystemMetrics':
        """Capture current system metrics."""
        try:
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            network = psutil.net_io_counters()
            disk_io = psutil.disk_io_counters()
            
            return cls(
                timestamp=datetime.utcnow(),
                cpu_percent=psutil.cpu_percent(interval=1),
                memory_percent=memory.percent,
                disk_usage_percent=disk.percent,
                network_io={
                    "bytes_sent": network.bytes_sent,
                    "bytes_recv": network.bytes_recv,
                    "packets_sent": network.packets_sent,
                    "packets_recv": network.packets_recv
                },
                disk_io={
                    "read_bytes": disk_io.read_bytes,
                    "write_bytes": disk_io.write_bytes,
                    "read_count": disk_io.read_count,
                    "write_count": disk_io.write_count
                },
                process_count=len(psutil.pids()),
                load_average=list(psutil.getloadavg()) if hasattr(psutil, 'getloadavg') else [0.0, 0.0, 0.0]
            )
        except Exception as e:
            logger.error(f"Failed to capture system metrics: {e}")
            return cls(
                timestamp=datetime.utcnow(),
                cpu_percent=0.0,
                memory_percent=0.0,
                disk_usage_percent=0.0,
                network_io={},
                disk_io={},
                process_count=0,
                load_average=[0.0, 0.0, 0.0]
            )


@dataclass
class LogEntry:
    """Structured log entry."""
    timestamp: datetime
    level: str
    source: str
    message: str
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class MonitoringAlert:
    """Monitoring alert generated by AI analysis."""
    id: str
    severity: AlertSeverity
    title: str
    description: str
    source: str
    detected_at: datetime
    metrics: Dict[str, Any]
    recommendations: List[str] = field(default_factory=list)
    auto_remediation: Optional[str] = None
    confidence_score: float = 0.0
    related_alerts: List[str] = field(default_factory=list)


class OllamaMonitor:
    """AI-powered system monitor using Ollama for intelligent analysis."""
    
    def __init__(self):
        # Monitoring configuration
        self.monitoring_interval = 30  # seconds
        self.log_analysis_interval = 300  # 5 minutes
        self.max_log_entries = 10000
        self.max_metrics_history = 2000
        
        # Data storage
        self.metrics_history: deque = deque(maxlen=self.max_metrics_history)
        self.log_buffer: deque = deque(maxlen=self.max_log_entries)
        self.active_alerts: Dict[str, MonitoringAlert] = {}
        self.alert_history: deque = deque(maxlen=1000)
        
        # Monitoring state
        self.monitoring_active = False
        self.monitoring_tasks: List[asyncio.Task] = []
        
        # Performance baselines (learned over time)
        self.performance_baselines: Dict[str, Dict] = {
            "cpu_normal_range": {"min": 0, "max": 80},
            "memory_normal_range": {"min": 0, "max": 85},
            "disk_normal_range": {"min": 0, "max": 90},
            "response_time_baseline": {"avg": 200, "p95": 500},  # milliseconds
            "error_rate_baseline": {"normal": 0.01, "warning": 0.05}  # percentage
        }
        
        # Pattern recognition
        self.known_patterns: Dict[str, Dict] = {}
        self.anomaly_threshold = 2.0  # Standard deviations
        
        # Log parsers for different sources
        self.log_parsers: Dict[str, Callable] = {}
        self._initialize_log_parsers()
        
        logger.info("OllamaMonitor initialized with AI-powered analysis capabilities")
    
    def _initialize_log_parsers(self):
        """Initialize log parsers for different log formats."""
        
        def parse_nginx_log(line: str) -> Optional[LogEntry]:
            """Parse nginx access log format."""
            nginx_pattern = r'(\S+) - - \[(.*?)\] "(\S+) (\S+) (\S+)" (\d+) (\d+) "(.*?)" "(.*?)"'
            match = re.match(nginx_pattern, line)
            if match:
                return LogEntry(
                    timestamp=datetime.strptime(match.group(2), "%d/%b/%Y:%H:%M:%S %z"),
                    level="INFO" if int(match.group(6)) < 400 else "ERROR",
                    source="nginx",
                    message=f"{match.group(3)} {match.group(4)} - {match.group(6)}",
                    metadata={
                        "ip": match.group(1),
                        "method": match.group(3),
                        "path": match.group(4),
                        "status": int(match.group(6)),
                        "size": int(match.group(7)),
                        "referer": match.group(8),
                        "user_agent": match.group(9)
                    }
                )
            return None
        
        def parse_application_log(line: str) -> Optional[LogEntry]:
            """Parse application log format."""
            app_pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}),\d+ - (\w+) - (\w+) - (.*)'
            match = re.match(app_pattern, line)
            if match:
                return LogEntry(
                    timestamp=datetime.strptime(match.group(1), "%Y-%m-%d %H:%M:%S"),
                    level=match.group(2),
                    source=match.group(3),
                    message=match.group(4)
                )
            return None
        
        def parse_system_log(line: str) -> Optional[LogEntry]:
            """Parse system log format."""
            syslog_pattern = r'(\w{3} \d{2} \d{2}:\d{2}:\d{2}) (\S+) (\S+): (.*)'
            match = re.match(syslog_pattern, line)
            if match:
                return LogEntry(
                    timestamp=datetime.strptime(f"{datetime.now().year} {match.group(1)}", "%Y %b %d %H:%M:%S"),
                    level="INFO",
                    source=match.group(3),
                    message=match.group(4),
                    metadata={"host": match.group(2)}
                )
            return None
        
        self.log_parsers = {
            "nginx": parse_nginx_log,
            "application": parse_application_log,
            "system": parse_system_log
        }
    
    async def start_monitoring(self):
        """Start all monitoring tasks."""
        if self.monitoring_active:
            logger.warning("Monitoring is already active")
            return
        
        self.monitoring_active = True
        
        # Start monitoring tasks
        self.monitoring_tasks = [
            asyncio.create_task(self._system_metrics_monitor()),
            asyncio.create_task(self._log_analysis_monitor()),
            asyncio.create_task(self._anomaly_detection_monitor()),
            asyncio.create_task(self._alert_management_monitor())
        ]
        
        logger.info("OllamaMonitor started all monitoring tasks")
    
    async def stop_monitoring(self):
        """Stop all monitoring tasks."""
        self.monitoring_active = False
        
        for task in self.monitoring_tasks:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
        
        self.monitoring_tasks.clear()
        logger.info("OllamaMonitor stopped all monitoring tasks")
    
    async def _system_metrics_monitor(self):
        """Monitor system metrics continuously."""
        while self.monitoring_active:
            try:
                # Capture current metrics
                metrics = SystemMetrics.capture_current()
                self.metrics_history.append(metrics)
                
                # Check for immediate issues
                await self._check_system_thresholds(metrics)
                
                # Update performance baselines
                await self._update_performance_baselines(metrics)
                
                await asyncio.sleep(self.monitoring_interval)
                
            except Exception as e:
                logger.error(f"System metrics monitoring error: {e}")
                await asyncio.sleep(self.monitoring_interval)
    
    async def _log_analysis_monitor(self):
        """Analyze logs periodically using AI."""
        while self.monitoring_active:
            try:
                if len(self.log_buffer) > 50:  # Minimum logs for analysis
                    await self._analyze_recent_logs()
                
                await asyncio.sleep(self.log_analysis_interval)
                
            except Exception as e:
                logger.error(f"Log analysis monitoring error: {e}")
                await asyncio.sleep(self.log_analysis_interval)
    
    async def _anomaly_detection_monitor(self):
        """Detect anomalies in system behavior."""
        while self.monitoring_active:
            try:
                if len(self.metrics_history) > 100:  # Need history for anomaly detection
                    await self._detect_anomalies()
                
                await asyncio.sleep(self.monitoring_interval * 2)  # Less frequent than metrics
                
            except Exception as e:
                logger.error(f"Anomaly detection error: {e}")
                await asyncio.sleep(self.monitoring_interval * 2)
    
    async def _alert_management_monitor(self):
        """Manage alerts and auto-remediation."""
        while self.monitoring_active:
            try:
                await self._process_active_alerts()
                await self._cleanup_resolved_alerts()
                
                await asyncio.sleep(60)  # Check every minute
                
            except Exception as e:
                logger.error(f"Alert management error: {e}")
                await asyncio.sleep(60)
    
    async def _check_system_thresholds(self, metrics: SystemMetrics):
        """Check if system metrics exceed thresholds."""
        alerts = []
        
        # CPU threshold check
        if metrics.cpu_percent > self.performance_baselines["cpu_normal_range"]["max"]:
            alerts.append(await self._create_threshold_alert(
                "cpu_high",
                AlertSeverity.WARNING if metrics.cpu_percent < 95 else AlertSeverity.CRITICAL,
                f"High CPU usage: {metrics.cpu_percent:.1f}%",
                metrics
            ))
        
        # Memory threshold check
        if metrics.memory_percent > self.performance_baselines["memory_normal_range"]["max"]:
            alerts.append(await self._create_threshold_alert(
                "memory_high",
                AlertSeverity.WARNING if metrics.memory_percent < 95 else AlertSeverity.CRITICAL,
                f"High memory usage: {metrics.memory_percent:.1f}%",
                metrics
            ))
        
        # Disk threshold check
        if metrics.disk_usage_percent > self.performance_baselines["disk_normal_range"]["max"]:
            alerts.append(await self._create_threshold_alert(
                "disk_high",
                AlertSeverity.ERROR if metrics.disk_usage_percent > 95 else AlertSeverity.WARNING,
                f"High disk usage: {metrics.disk_usage_percent:.1f}%",
                metrics
            ))
        
        # Process each alert
        for alert in alerts:
            if alert:
                await self._process_new_alert(alert)
    
    async def _create_threshold_alert(
        self,
        alert_type: str,
        severity: AlertSeverity,
        title: str,
        metrics: SystemMetrics
    ) -> Optional[MonitoringAlert]:
        """Create a threshold-based alert with AI analysis."""
        
        try:
            # Use AI to analyze the threshold breach
            analysis_task = OllamaTask(
                task_type=OllamaTaskType.SYSTEM_ANALYSIS,
                input_data=f"""
                System threshold breach detected:
                Alert Type: {alert_type}
                Current Metrics: {json.dumps(metrics.__dict__, default=str, indent=2)}
                Severity: {severity.value}
                
                Analyze the situation and provide:
                1. Root cause analysis
                2. Immediate recommendations
                3. Preventive measures
                4. Auto-remediation suggestions if any
                """,
                context={
                    "alert_type": alert_type,
                    "severity": severity.value,
                    "historical_data": self._get_recent_metrics_summary()
                },
                temperature=0.3
            )
            
            ai_result = await ollama_everything.process_task(analysis_task)
            
            if ai_result.error:
                logger.error(f"AI analysis failed for threshold alert: {ai_result.error}")
                recommendations = [f"Investigate {alert_type} threshold breach"]
                auto_remediation = None
            else:
                # Parse AI recommendations
                analysis = ai_result.result
                recommendations = self._extract_recommendations_from_analysis(analysis)
                auto_remediation = self._extract_auto_remediation(analysis)
            
            alert_id = f"{alert_type}_{int(time.time())}"
            
            return MonitoringAlert(
                id=alert_id,
                severity=severity,
                title=title,
                description=f"System {alert_type} threshold exceeded",
                source="system_monitor",
                detected_at=metrics.timestamp,
                metrics=metrics.__dict__,
                recommendations=recommendations,
                auto_remediation=auto_remediation,
                confidence_score=ai_result.confidence_score if not ai_result.error else 0.8
            )
            
        except Exception as e:
            logger.error(f"Failed to create threshold alert: {e}")
            return None
    
    async def _analyze_recent_logs(self):
        """Analyze recent logs using AI for patterns and issues."""
        
        # Get recent logs (last 100)
        recent_logs = list(self.log_buffer)[-100:]
        if not recent_logs:
            return
        
        # Group logs by level and source
        log_summary = self._summarize_logs(recent_logs)
        
        # Use AI to analyze log patterns
        analysis_task = OllamaTask(
            task_type=OllamaTaskType.LOG_ANALYSIS,
            input_data=json.dumps(log_summary, indent=2),
            context={
                "analysis_type": "log_pattern_analysis",
                "time_window": "recent_logs",
                "log_count": len(recent_logs)
            },
            temperature=0.4
        )
        
        try:
            ai_result = await ollama_everything.process_task(analysis_task)
            
            if ai_result.error:
                logger.error(f"AI log analysis failed: {ai_result.error}")
                return
            
            # Process AI analysis results
            await self._process_log_analysis_results(ai_result, recent_logs)
            
        except Exception as e:
            logger.error(f"Log analysis failed: {e}")
    
    def _summarize_logs(self, logs: List[LogEntry]) -> Dict[str, Any]:
        """Summarize logs for AI analysis."""
        summary = {
            "total_logs": len(logs),
            "time_range": {
                "start": min(log.timestamp for log in logs).isoformat(),
                "end": max(log.timestamp for log in logs).isoformat()
            },
            "levels": defaultdict(int),
            "sources": defaultdict(int),
            "error_samples": [],
            "warning_samples": [],
            "patterns": {}
        }
        
        for log in logs:
            summary["levels"][log.level] += 1
            summary["sources"][log.source] += 1
            
            # Collect error and warning samples
            if log.level == "ERROR" and len(summary["error_samples"]) < 10:
                summary["error_samples"].append({
                    "timestamp": log.timestamp.isoformat(),
                    "source": log.source,
                    "message": log.message[:200]
                })
            elif log.level == "WARNING" and len(summary["warning_samples"]) < 5:
                summary["warning_samples"].append({
                    "timestamp": log.timestamp.isoformat(),
                    "source": log.source,
                    "message": log.message[:200]
                })
        
        return summary
    
    async def _process_log_analysis_results(self, ai_result: OllamaResult, logs: List[LogEntry]):
        """Process the results of AI log analysis."""
        
        analysis = ai_result.result
        
        # Extract insights from AI analysis
        insights = self._extract_log_insights(analysis)
        
        # Create alerts based on AI findings
        for insight in insights:
            if insight.get("severity") in ["high", "critical"]:
                alert = MonitoringAlert(
                    id=f"log_analysis_{int(time.time())}_{hash(insight.get('title', ''))%1000}",
                    severity=AlertSeverity.ERROR if insight.get("severity") == "critical" else AlertSeverity.WARNING,
                    title=insight.get("title", "Log Analysis Alert"),
                    description=insight.get("description", "Anomaly detected in log analysis"),
                    source="log_analyzer",
                    detected_at=datetime.utcnow(),
                    metrics={"log_count": len(logs)},
                    recommendations=insight.get("recommendations", []),
                    confidence_score=ai_result.confidence_score
                )
                
                await self._process_new_alert(alert)
    
    def _extract_log_insights(self, analysis: Any) -> List[Dict[str, Any]]:
        """Extract actionable insights from log analysis."""
        insights = []
        
        analysis_str = str(analysis)
        
        # Look for pattern indicators
        if "error rate" in analysis_str.lower():
            insights.append({
                "title": "High Error Rate Detected",
                "description": "Analysis indicates elevated error rates",
                "severity": "high",
                "recommendations": ["Investigate error patterns", "Check system resources"]
            })
        
        if "performance" in analysis_str.lower() and ("slow" in analysis_str.lower() or "delay" in analysis_str.lower()):
            insights.append({
                "title": "Performance Issues Detected",
                "description": "Log analysis indicates performance degradation",
                "severity": "medium",
                "recommendations": ["Check system performance", "Review resource usage"]
            })
        
        if "security" in analysis_str.lower() or "attack" in analysis_str.lower():
            insights.append({
                "title": "Security Concern Detected",
                "description": "Potential security issues found in logs",
                "severity": "critical",
                "recommendations": ["Review security logs", "Check for intrusion attempts"]
            })
        
        return insights
    
    async def _detect_anomalies(self):
        """Detect anomalies in system metrics using statistical analysis and AI."""
        
        if len(self.metrics_history) < 100:
            return
        
        # Get recent metrics for analysis
        recent_metrics = list(self.metrics_history)[-100:]
        
        # Calculate statistical baselines
        cpu_values = [m.cpu_percent for m in recent_metrics]
        memory_values = [m.memory_percent for m in recent_metrics]
        
        cpu_mean = statistics.mean(cpu_values)
        cpu_stdev = statistics.stdev(cpu_values) if len(cpu_values) > 1 else 0
        
        memory_mean = statistics.mean(memory_values)
        memory_stdev = statistics.stdev(memory_values) if len(memory_values) > 1 else 0
        
        # Check for statistical anomalies
        current_metrics = recent_metrics[-1]
        
        cpu_z_score = (current_metrics.cpu_percent - cpu_mean) / max(cpu_stdev, 0.1)
        memory_z_score = (current_metrics.memory_percent - memory_mean) / max(memory_stdev, 0.1)
        
        anomalies = []
        
        if abs(cpu_z_score) > self.anomaly_threshold:
            anomalies.append(f"CPU usage anomaly: {current_metrics.cpu_percent:.1f}% (z-score: {cpu_z_score:.2f})")
        
        if abs(memory_z_score) > self.anomaly_threshold:
            anomalies.append(f"Memory usage anomaly: {current_metrics.memory_percent:.1f}% (z-score: {memory_z_score:.2f})")
        
        if anomalies:
            # Use AI to analyze the anomalies
            await self._analyze_anomalies_with_ai(anomalies, recent_metrics)
    
    async def _analyze_anomalies_with_ai(self, anomalies: List[str], metrics_history: List[SystemMetrics]):
        """Use AI to analyze detected anomalies."""
        
        metrics_summary = {
            "anomalies": anomalies,
            "current_metrics": metrics_history[-1].__dict__,
            "trend_data": {
                "cpu_trend": [m.cpu_percent for m in metrics_history[-20:]],
                "memory_trend": [m.memory_percent for m in metrics_history[-20:]],
                "load_trend": [m.load_average[0] for m in metrics_history[-20:] if m.load_average]
            }
        }
        
        analysis_task = OllamaTask(
            task_type=OllamaTaskType.ANOMALY_DETECTION,
            input_data=json.dumps(metrics_summary, default=str, indent=2),
            context={
                "analysis_type": "anomaly_investigation",
                "anomaly_count": len(anomalies)
            },
            temperature=0.3
        )
        
        try:
            ai_result = await ollama_everything.process_task(analysis_task)
            
            if not ai_result.error:
                # Create alert based on AI analysis
                alert = MonitoringAlert(
                    id=f"anomaly_{int(time.time())}",
                    severity=AlertSeverity.WARNING,
                    title="System Anomaly Detected",
                    description=f"Statistical anomalies detected: {', '.join(anomalies)}",
                    source="anomaly_detector",
                    detected_at=datetime.utcnow(),
                    metrics=metrics_summary,
                    recommendations=self._extract_recommendations_from_analysis(ai_result.result),
                    confidence_score=ai_result.confidence_score
                )
                
                await self._process_new_alert(alert)
                
        except Exception as e:
            logger.error(f"AI anomaly analysis failed: {e}")
    
    async def _process_new_alert(self, alert: MonitoringAlert):
        """Process a newly created alert."""
        
        # Check if similar alert already exists
        existing_alert = self._find_similar_alert(alert)
        if existing_alert:
            logger.info(f"Similar alert already exists: {existing_alert.id}")
            return
        
        # Add to active alerts
        self.active_alerts[alert.id] = alert
        self.alert_history.append(alert)
        
        # Log the alert
        logger.warning(f"NEW ALERT [{alert.severity.value.upper()}]: {alert.title} - {alert.description}")
        
        # Attempt auto-remediation if available
        if alert.auto_remediation and alert.severity in [AlertSeverity.WARNING, AlertSeverity.ERROR]:
            await self._attempt_auto_remediation(alert)
        
        # Store alert in persistent storage
        await self._store_alert(alert)
    
    def _find_similar_alert(self, new_alert: MonitoringAlert) -> Optional[MonitoringAlert]:
        """Find if a similar alert already exists."""
        for alert in self.active_alerts.values():
            if (alert.source == new_alert.source and 
                alert.title == new_alert.title and
                abs((alert.detected_at - new_alert.detected_at).total_seconds()) < 300):  # 5 minutes
                return alert
        return None
    
    async def _attempt_auto_remediation(self, alert: MonitoringAlert):
        """Attempt automatic remediation for an alert."""
        
        if not alert.auto_remediation:
            return
        
        try:
            logger.info(f"Attempting auto-remediation for alert {alert.id}: {alert.auto_remediation}")
            
            # Use AI to generate specific remediation commands
            remediation_task = OllamaTask(
                task_type=OllamaTaskType.CODE_GENERATION,
                input_data=f"""
                Generate safe system commands to remediate this issue:
                Alert: {alert.title}
                Description: {alert.description}
                Suggested Remediation: {alert.auto_remediation}
                System Metrics: {json.dumps(alert.metrics, default=str)}
                
                Generate bash/shell commands that are:
                1. Safe to execute automatically
                2. Non-destructive
                3. Focused on the specific issue
                4. Include verification steps
                """,
                context={"remediation_type": "system_automation"},
                temperature=0.2
            )
            
            ai_result = await ollama_everything.process_task(remediation_task)
            
            if not ai_result.error:
                commands = self._extract_remediation_commands(ai_result.result)
                
                if commands:
                    logger.info(f"Generated remediation commands: {commands}")
                    # Note: In production, you would implement safe command execution
                    # For now, we just log the suggested commands
                    alert.recommendations.extend([f"Auto-generated command: {cmd}" for cmd in commands[:3]])
            
        except Exception as e:
            logger.error(f"Auto-remediation failed for alert {alert.id}: {e}")
    
    def _extract_remediation_commands(self, ai_result: Any) -> List[str]:
        """Extract safe remediation commands from AI response."""
        commands = []
        result_str = str(ai_result)
        
        # Look for command patterns
        command_patterns = [
            r'```bash\n(.*?)\n```',
            r'```sh\n(.*?)\n```',
            r'```\n(.*?)\n```'
        ]
        
        for pattern in command_patterns:
            matches = re.findall(pattern, result_str, re.DOTALL)
            for match in matches:
                # Filter for safe commands only
                lines = match.strip().split('\n')
                for line in lines:
                    line = line.strip()
                    if line and self._is_safe_command(line):
                        commands.append(line)
        
        return commands[:5]  # Limit to 5 commands
    
    def _is_safe_command(self, command: str) -> bool:
        """Check if a command is safe for auto-execution."""
        
        # List of safe command prefixes
        safe_prefixes = [
            "systemctl restart",
            "systemctl reload",
            "service restart",
            "pkill -HUP",
            "docker restart",
            "kubectl rollout restart",
            "pm2 restart",
            "supervisorctl restart"
        ]
        
        # Dangerous command patterns to avoid
        dangerous_patterns = [
            "rm -rf",
            "dd if=",
            "mkfs",
            "fdisk",
            "shutdown",
            "reboot",
            "halt",
            "> /dev/",
            "chmod 777",
            "chown -R"
        ]
        
        command_lower = command.lower()
        
        # Check for dangerous patterns
        for pattern in dangerous_patterns:
            if pattern in command_lower:
                return False
        
        # Check for safe prefixes
        for prefix in safe_prefixes:
            if command_lower.startswith(prefix):
                return True
        
        return False
    
    async def _process_active_alerts(self):
        """Process and update active alerts."""
        
        for alert_id, alert in list(self.active_alerts.items()):
            # Check if alert conditions are still present
            if await self._is_alert_condition_resolved(alert):
                logger.info(f"Alert {alert_id} condition resolved")
                alert.metadata["resolved_at"] = datetime.utcnow().isoformat()
                del self.active_alerts[alert_id]
    
    async def _is_alert_condition_resolved(self, alert: MonitoringAlert) -> bool:
        """Check if the condition that triggered an alert is resolved."""
        
        if not self.metrics_history:
            return False
        
        current_metrics = self.metrics_history[-1]
        
        # Check based on alert source
        if "cpu_high" in alert.id:
            return current_metrics.cpu_percent < self.performance_baselines["cpu_normal_range"]["max"]
        elif "memory_high" in alert.id:
            return current_metrics.memory_percent < self.performance_baselines["memory_normal_range"]["max"]
        elif "disk_high" in alert.id:
            return current_metrics.disk_usage_percent < self.performance_baselines["disk_normal_range"]["max"]
        
        # For other alerts, consider them resolved after 1 hour
        return (datetime.utcnow() - alert.detected_at).total_seconds() > 3600
    
    async def _cleanup_resolved_alerts(self):
        """Clean up old resolved alerts from history."""
        cutoff_time = datetime.utcnow() - timedelta(hours=24)
        
        # Keep only alerts from last 24 hours
        self.alert_history = deque([
            alert for alert in self.alert_history 
            if alert.detected_at > cutoff_time
        ], maxlen=1000)
    
    async def _update_performance_baselines(self, metrics: SystemMetrics):
        """Update performance baselines based on historical data."""
        
        if len(self.metrics_history) < 100:
            return
        
        # Calculate new baselines from recent data
        recent_metrics = list(self.metrics_history)[-100:]
        
        cpu_values = [m.cpu_percent for m in recent_metrics]
        memory_values = [m.memory_percent for m in recent_metrics]
        
        # Update baselines with 95th percentile
        self.performance_baselines["cpu_normal_range"]["max"] = statistics.quantiles(cpu_values, n=20)[18]  # 95th percentile
        self.performance_baselines["memory_normal_range"]["max"] = statistics.quantiles(memory_values, n=20)[18]
    
    def _get_recent_metrics_summary(self) -> Dict[str, Any]:
        """Get a summary of recent metrics for AI context."""
        if not self.metrics_history:
            return {}
        
        recent = list(self.metrics_history)[-20:]  # Last 20 metrics
        
        return {
            "cpu_avg": statistics.mean([m.cpu_percent for m in recent]),
            "memory_avg": statistics.mean([m.memory_percent for m in recent]),
            "disk_usage": recent[-1].disk_usage_percent,
            "process_count": recent[-1].process_count,
            "trends": {
                "cpu_increasing": recent[-1].cpu_percent > recent[0].cpu_percent,
                "memory_increasing": recent[-1].memory_percent > recent[0].memory_percent
            }
        }
    
    def _extract_recommendations_from_analysis(self, analysis: Any) -> List[str]:
        """Extract actionable recommendations from AI analysis."""
        recommendations = []
        analysis_str = str(analysis)
        
        # Look for recommendation patterns
        patterns = [
            r'recommend(?:ation)?s?[:\s]+(.*?)(?:\n|$)',
            r'suggest(?:ion)?s?[:\s]+(.*?)(?:\n|$)',
            r'action(?:s)?[:\s]+(.*?)(?:\n|$)',
            r'\d+\.\s*(.*?)(?:\n|$)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, analysis_str, re.IGNORECASE | re.MULTILINE)
            recommendations.extend([m.strip() for m in matches if len(m.strip()) > 10])
        
        # Clean and deduplicate
        return list(set(recommendations))[:10]
    
    def _extract_auto_remediation(self, analysis: Any) -> Optional[str]:
        """Extract auto-remediation suggestions from AI analysis."""
        analysis_str = str(analysis)
        
        auto_patterns = [
            r'auto[_\s]*remediation[:\s]+(.*?)(?:\n|$)',
            r'automatic[_\s]*fix[:\s]+(.*?)(?:\n|$)',
            r'can[_\s]*fix[:\s]*automatically[:\s]+(.*?)(?:\n|$)'
        ]
        
        for pattern in auto_patterns:
            match = re.search(pattern, analysis_str, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return None
    
    async def _store_alert(self, alert: MonitoringAlert):
        """Store alert in persistent storage."""
        try:
            alert_data = {
                "id": alert.id,
                "severity": alert.severity.value,
                "title": alert.title,
                "description": alert.description,
                "source": alert.source,
                "detected_at": alert.detected_at.isoformat(),
                "metrics": alert.metrics,
                "recommendations": alert.recommendations,
                "auto_remediation": alert.auto_remediation,
                "confidence_score": alert.confidence_score,
                "metadata": alert.__dict__
            }
            
            async with valkey_connection_manager.get_client() as client:
                await client.setex(
                    f"ollama_monitor_alert:{alert.id}",
                    86400,  # 24 hours
                    json.dumps(alert_data, default=str)
                )
                
        except Exception as e:
            logger.error(f"Failed to store alert {alert.id}: {e}")
    
    # Public API methods
    
    async def ingest_log_line(self, log_line: str, source: str = "application"):
        """Ingest a single log line for analysis."""
        
        # Parse the log line
        parser = self.log_parsers.get(source, self.log_parsers["application"])
        log_entry = parser(log_line)
        
        if log_entry:
            self.log_buffer.append(log_entry)
        else:
            # Fallback: create basic log entry
            self.log_buffer.append(LogEntry(
                timestamp=datetime.utcnow(),
                level="INFO",
                source=source,
                message=log_line
            ))
    
    async def ingest_logs_bulk(self, log_lines: List[str], source: str = "application"):
        """Ingest multiple log lines efficiently."""
        for log_line in log_lines:
            await self.ingest_log_line(log_line, source)
    
    async def analyze_specific_issue(self, issue_description: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Analyze a specific issue using AI with current system context."""
        
        current_metrics = self.metrics_history[-1] if self.metrics_history else None
        recent_logs = list(self.log_buffer)[-50:]
        
        analysis_context = {
            "issue_description": issue_description,
            "current_metrics": current_metrics.__dict__ if current_metrics else {},
            "recent_alerts": len(self.active_alerts),
            "recent_logs_summary": self._summarize_logs(recent_logs),
            **(context or {})
        }
        
        analysis_task = OllamaTask(
            task_type=OllamaTaskType.ERROR_DIAGNOSIS,
            input_data=json.dumps(analysis_context, default=str, indent=2),
            context={"analysis_type": "specific_issue_investigation"},
            temperature=0.3
        )
        
        try:
            result = await ollama_everything.process_task(analysis_task)
            
            return {
                "analysis": result.result,
                "confidence": result.confidence_score,
                "recommendations": self._extract_recommendations_from_analysis(result.result),
                "error": result.error
            }
            
        except Exception as e:
            logger.error(f"Specific issue analysis failed: {e}")
            return {"error": str(e)}
    
    async def get_monitoring_status(self) -> Dict[str, Any]:
        """Get comprehensive monitoring status."""
        
        current_metrics = self.metrics_history[-1] if self.metrics_history else None
        
        return {
            "monitoring_active": self.monitoring_active,
            "current_metrics": current_metrics.__dict__ if current_metrics else {},
            "active_alerts_count": len(self.active_alerts),
            "alert_history_count": len(self.alert_history),
            "metrics_history_count": len(self.metrics_history),
            "log_buffer_count": len(self.log_buffer),
            "performance_baselines": self.performance_baselines,
            "recent_alerts": [
                {
                    "id": alert.id,
                    "severity": alert.severity.value,
                    "title": alert.title,
                    "detected_at": alert.detected_at.isoformat()
                }
                for alert in list(self.active_alerts.values())
            ]
        }
    
    async def shutdown(self):
        """Shutdown the monitoring system."""
        try:
            await self.stop_monitoring()
            
            # Save final state
            await self._save_monitoring_state()
            
            logger.info("OllamaMonitor shutdown completed")
            
        except Exception as e:
            logger.error(f"Error during monitor shutdown: {e}")
    
    async def _save_monitoring_state(self):
        """Save monitoring state to persistent storage."""
        try:
            state_data = {
                "performance_baselines": self.performance_baselines,
                "alert_history": [alert.__dict__ for alert in list(self.alert_history)[-100:]],
                "metrics_summary": self._get_recent_metrics_summary(),
                "last_updated": datetime.utcnow().isoformat()
            }
            
            async with valkey_connection_manager.get_client() as client:
                await client.setex(
                    "ollama_monitor_state",
                    86400 * 7,  # 7 days
                    json.dumps(state_data, default=str)
                )
                
        except Exception as e:
            logger.warning(f"Failed to save monitoring state: {e}")


# Global monitor instance
ollama_monitor = OllamaMonitor()


# Convenience functions
async def start_ollama_monitoring():
    """Start Ollama-powered monitoring."""
    return await ollama_monitor.start_monitoring()


async def stop_ollama_monitoring():
    """Stop Ollama-powered monitoring."""
    return await ollama_monitor.stop_monitoring()


async def log_to_ollama_monitor(message: str, level: str = "INFO", source: str = "application"):
    """Log a message to the Ollama monitor for analysis."""
    log_line = f"{datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} - {level} - {source} - {message}"
    await ollama_monitor.ingest_log_line(log_line, source)


async def analyze_issue_with_ai(issue_description: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
    """Analyze a specific issue using AI."""
    return await ollama_monitor.analyze_specific_issue(issue_description, context)


async def get_ai_monitoring_status() -> Dict[str, Any]:
    """Get current AI monitoring status."""
    return await ollama_monitor.get_monitoring_status()


# Initialize and shutdown functions
async def initialize_ollama_monitor():
    """Initialize the Ollama monitor system."""
    try:
        # Load existing monitoring state
        async with valkey_connection_manager.get_client() as client:
            state_data = await client.get("ollama_monitor_state")
            
            if state_data:
                data = json.loads(state_data)
                ollama_monitor.performance_baselines = data.get("performance_baselines", ollama_monitor.performance_baselines)
                
                logger.info("Loaded monitoring state from persistent storage")
        
        # Start monitoring
        await ollama_monitor.start_monitoring()
        
        logger.info("OllamaMonitor initialized and started successfully")
        
    except Exception as e:
        logger.error(f"Failed to initialize OllamaMonitor: {e}")
        raise


async def shutdown_ollama_monitor():
    """Shutdown the Ollama monitor system."""
    try:
        await ollama_monitor.shutdown()
        logger.info("OllamaMonitor shutdown completed")
        
    except Exception as e:
        logger.error(f"Error shutting down OllamaMonitor: {e}")